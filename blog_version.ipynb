{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detector choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for img_annot in annot:\n",
    "    tree = ET.parse(img_annot)\n",
    "    root = tree.getroot()\n",
    "    file = root.find('filename').text\n",
    "    file_path = img_dir + file\n",
    "    img = cv.imread(file_path)\n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "    x = img.shape[1]/width\n",
    "    y = img.shape[0]/height\n",
    "    objects = root.findall('object')\n",
    "    for object in objects:\n",
    "        label = object.find('name').text\n",
    "        labels.append(label)\n",
    "        bndbox = object.find('bndbox')\n",
    "        xmin = int((int(bndbox.find('xmin').text))/x)\n",
    "        ymin = int((int(bndbox.find('ymin').text))/y)\n",
    "        xmax = int((int(bndbox.find('xmax').text))/x)\n",
    "        ymax = int((int(bndbox.find('ymax').text))/y)\n",
    "        face = img[ymin:ymax, xmin:xmax]\n",
    "        images.append(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lbl):\n",
    "    if lbl == 'with_mask':\n",
    "        return 2\n",
    "    if lbl == 'mask_weared_incorrect':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = [encode(lbl) for lbl in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Characteristic points - 432 check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_files = [img for img in glob.glob(\"dataset/first_approach/with_mask/*.jpg\")]\n",
    "unmasked_files = [img for img in glob.glob(\"dataset/first_approach/without_mask/*.jpg\")]\n",
    "incorrect_files = [img for img in glob.glob(\"dataset/first_approach/incorrect_mask/*.jpg\")]\n",
    "masked = [cv.imread(img) for img in masked_files if cv.imread(img) is not None]\n",
    "unmasked = [cv.imread(img) for img in unmasked_files if cv.imread(img) is not None]\n",
    "incorrect = [cv.imread(img) for img in incorrect_files if cv.imread(img) is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See exemplary images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15, 10))\n",
    "axes = []\n",
    "for i in range(4):\n",
    "    img = cv.cvtColor(incorrect[i], cv.COLOR_BGR2RGB)\n",
    "    axes.append(fig.add_subplot(1, 4, i+1))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is not good. The images have watermarks and may be rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15, 10))\n",
    "axes = []\n",
    "for i in range(4):\n",
    "    img = cv.cvtColor(masked[i], cv.COLOR_BGR2RGB)\n",
    "    axes.append(fig.add_subplot(1, 4, i+1))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15, 10))\n",
    "axes = []\n",
    "for i in range(4):\n",
    "    img = cv.cvtColor(unmasked[i], cv.COLOR_BGR2RGB)\n",
    "    axes.append(fig.add_subplot(1, 4, i+1))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation I will use OpenCV's Haar Cascades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv.CascadeClassifier('models/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this model, I have to convert my images into the greyscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detector may detect multiple faces in the picture. I shall use them all in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_detected = [unmasked[0], masked[0], incorrect[0], unmasked[1], masked[1], incorrect[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(7.5, 5))\n",
    "axes = []\n",
    "for i in range(len(show_detected)):\n",
    "    img_display = show_detected[i]\n",
    "    img = cv.cvtColor(img_display, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(img, scaleFactor = 1.2, minNeighbors = 5)\n",
    "    for (a, b, c, d) in faces:\n",
    "        cv.rectangle(img_display, (a, b), (a+c, b+d), (0, 0, 255), 2)\n",
    "    img = cv.cvtColor(img_display, cv.COLOR_BGR2RGB)\n",
    "    axes.append(fig.add_subplot(2, 3, i+1))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(masked))\n",
    "print(len(unmasked))\n",
    "print(len(incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detected faces could be of different sizes - I need to rescale them before feeding them into another classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(img, model, scaleFactor=1.2, \n",
    "              minNeighbors=5, dimensions=(240, 240), for_display=False):\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = model.detectMultiScale(img_gray, scaleFactor = scaleFactor, \n",
    "                                   minNeighbors = minNeighbors)\n",
    "    extracted = []\n",
    "    coords = []\n",
    "    for (a, b, c, d) in faces:\n",
    "        crop_img = img_gray[b:b+d, a:a+c]\n",
    "        if crop_img.size != 0 and crop_img.size != 1:\n",
    "            crop_img = cv.resize(crop_img, dimensions)\n",
    "            extracted.append(crop_img)\n",
    "    if len(extracted) == 0:\n",
    "        return None\n",
    "    if for_display:\n",
    "        return extracted, faces\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfaces = [get_faces(image, face_detector) for image in masked]\n",
    "mfaces = [face for image in mfaces if image is not None for face in image]\n",
    "\n",
    "ufaces = [get_faces(image, face_detector) for image in unmasked]\n",
    "ufaces = [face for image in ufaces if image is not None for face in image]\n",
    "\n",
    "ifaces = [get_faces(image, face_detector) for image in incorrect]\n",
    "ifaces = [face for image in ifaces if image is not None for face in image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mfaces))\n",
    "print(len(ufaces))\n",
    "print(len(ifaces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the used face detector didn't work very well. It will most definitely hinder model's overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should prepare the labels for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfaces_lbl = [2]* len(mfaces)\n",
    "ifaces_lbl = [1]* len(ifaces)\n",
    "ufaces_lbl = [0]* len(ufaces)\n",
    "y = mfaces_lbl + ifaces_lbl + ufaces_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " x= np.concatenate((mfaces, ifaces, ufaces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And flatten the data for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (np.array(x)).reshape(len(y), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, \n",
    "                                                    random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_detector = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_detector.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the application results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread(\"dataset/other.png\")\n",
    "img2 = cv.imread(\"dataset/other_example.png\")\n",
    "img3 = cv.imread(\"dataset/second_approach/images/maksssksksss195.png\")\n",
    "img4 = cv.imread(\"dataset/second_approach/images/maksssksksss211.png\")\n",
    "test_imgs = [img1, img2, img3, img4]\n",
    "fig=plt.figure(figsize=(15, 10))\n",
    "axes = []\n",
    "for i in range(4):\n",
    "    img = cv.cvtColor(test_imgs[i], cv.COLOR_BGR2RGB)\n",
    "    axes.append(fig.add_subplot(1, 4, i+1))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_result = [\"No mask!\", \"Incorrect!\", \"Mask\"]\n",
    "mask_coloring = [(255, 0, 0), (255, 0, 0), (0, 255, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_coloring = [(255, 0, 0), (255, 0, 0), (0, 255, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,10))\n",
    "axes = []\n",
    "for i in range(4):\n",
    "    img = test_imgs[i]\n",
    "    if get_faces(img, face_detector) is not None:\n",
    "        faces, coords = get_faces(img, face_detector, for_display=True)\n",
    "        faces = [face for image in faces for face in image]\n",
    "        faces_flattened = (np.array(faces)).reshape((len(coords), -1))\n",
    "        res = mask_detector.predict(faces_flattened)\n",
    "        img_display = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        j = 0\n",
    "        for coord in coords:\n",
    "            cv.rectangle(img_display, (coord[0], coord[1]), (coord[0]+coord[2], coord[1]+coord[3]), mask_coloring[res[j]], 2)\n",
    "            cv.putText(img_display,mask_result[res[j]],(coord[0], coord[1]-10), fontFace = font, fontScale=1, color=mask_coloring[res[j]],thickness=1, lineType=cv.LINE_AA)\n",
    "            j += 1\n",
    "    else:\n",
    "        img_display = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    axes.append(fig.add_subplot(2, 2, i+1))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_display) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change of face detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv.dnn.readNetFromCaffe(\"models/deploy.prototxt.txt\", \"models/res10_300x300_ssd_iter_140000.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(img, model, dimensions=(240, 240), for_display=False):\n",
    "    h, w = img.shape[:2]\n",
    "    blob = cv.dnn.blobFromImage(cv.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 117.0, 123.0))\n",
    "    model.setInput(blob)\n",
    "    detected = model.forward()\n",
    "    extracted = []\n",
    "    coordinates = []\n",
    "    for i in range(detected.shape[2]):\n",
    "        confidence = detected[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = detected[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            coords = box.astype(\"int\")\n",
    "            crop_img = img[coords[1]:coords[3], coords[0]:coords[2]]\n",
    "            crop_img = cv.resize(crop_img, dimensions)\n",
    "            # crop_img = cv.cvtColor(crop_img, cv.COLOR_BGR2GRAY)\n",
    "            extracted.append(crop_img)\n",
    "            if for_display:\n",
    "                coordinates.append(coords)\n",
    "    if len(extracted)==0:\n",
    "        return None\n",
    "    if for_display:\n",
    "        return extracted, coordinates\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfaces = [get_faces(image, face_detector) for image in masked]\n",
    "mfaces = [face for image in mfaces if image is not None for face in image]\n",
    "\n",
    "ufaces = [get_faces(image, face_detector) for image in unmasked]\n",
    "ufaces = [face for image in ufaces if image is not None for face in image]\n",
    "\n",
    "ifaces = [get_faces(image, face_detector) for image in incorrect]\n",
    "ifaces = [face for image in ifaces if image is not None for face in image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mfaces))\n",
    "print(len(ufaces))\n",
    "print(len(ifaces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfaces1 = [get_faces(image, face_detector) for image in masked]\n",
    "mfaces1 = [i for i in mfaces1 if i is not None]\n",
    "ufaces1 = [get_faces(image, face_detector) for image in unmasked]\n",
    "ufaces1 = [i for i in ufaces1 if i is not None]\n",
    "ifaces1= [get_faces(image, face_detector) for image in incorrect]\n",
    "ifaces1 = [i for i in ifaces1 if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(8, 15))\n",
    "axes = []\n",
    "j = 0\n",
    "for i in range(len(mfaces1)):\n",
    "    if (len(mfaces1[i]) != 1):\n",
    "        for face in mfaces1[i]:\n",
    "            img = cv.cvtColor(face, cv.COLOR_BGR2RGB)\n",
    "            axes.append(fig.add_subplot(8, 5, j+1))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img)\n",
    "            j += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(8,20))\n",
    "axes = []\n",
    "j = 0\n",
    "for i in range(len(ufaces1)):\n",
    "    if (len(ufaces1[i]) != 1):\n",
    "        for face in ufaces1[i]:\n",
    "            img = cv.cvtColor(face, cv.COLOR_BGR2RGB)\n",
    "            axes.append(fig.add_subplot(20, 8, j+1))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img)\n",
    "            j += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(4,20))\n",
    "axes = []\n",
    "j = 0\n",
    "for i in range(len(ifaces1)):\n",
    "    if (len(ifaces1[i]) != 1):\n",
    "        for face in ifaces1[i]:\n",
    "            img = cv.cvtColor(face, cv.COLOR_BGR2RGB)\n",
    "            axes.append(fig.add_subplot(20, 4, j+1))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img)\n",
    "            j += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2 - old version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for previous classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1 = [cv.resize(face, (240, 240)) for face in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1 = [image.flatten() for image in images1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images1, lbls, test_size=0.2, \n",
    "                                                    random_state=1, stratify=lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_detector = RandomForestClassifier().fit(X_train, y_train)\n",
    "mask_detector.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the results are better even for the sole dataset itself. Let's check it out on the other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = [masked[1], unmasked[1], incorrect[0],\n",
    "            masked[2], unmasked[2], incorrect[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,10))\n",
    "axes = []\n",
    "for i in range(6):\n",
    "    img = test_imgs[i]\n",
    "    if get_faces(img, face_detector) is not None:\n",
    "        faces, coords = get_faces(img, face_detector, for_display=True)\n",
    "        faces_flattened = (np.array(faces)).reshape((len(coords), -1))\n",
    "        faces = [face for image in faces for face in image]\n",
    "        res = mask_detector.predict(faces_flattened)\n",
    "        img_display = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        j = 0\n",
    "        for coord in coords:\n",
    "            cv.rectangle(img_display, (coord[0], coord[1]), (coord[2], coord[3]), mask_coloring[res[j]], 2)\n",
    "            cv.putText(img_display, mask_result[res[j]],(coord[0], coord[1]-10), fontFace = font, fontScale=1, color=mask_coloring[res[j]],thickness=1, lineType=cv.LINE_AA)\n",
    "            j += 1\n",
    "    else:\n",
    "        img_display = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        plt.title(\"No face detected\")\n",
    "    axes.append(fig.add_subplot(2, 3, i+1))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_display) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
